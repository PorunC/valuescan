"""
å¸å®‰ Alpha ä¸Žåˆçº¦ä»£å¸äº¤é›†ç¼“å­˜æ¨¡å—
å®šæœŸä»Ž API èŽ·å–äº¤é›†æ•°æ®å¹¶ç¼“å­˜åˆ°å†…å­˜
"""

import json
import threading
import time
from datetime import datetime, timezone, timedelta
from pathlib import Path

try:
    from .logger import logger
except ImportError:
    from logger import logger

# å¯¼å…¥ä»£ç†é…ç½®
try:
    from .config import SOCKS5_PROXY, HTTP_PROXY
except ImportError:
    try:
        from config import SOCKS5_PROXY, HTTP_PROXY
    except ImportError:
        SOCKS5_PROXY = ""
        HTTP_PROXY = ""

try:
    import requests
except ImportError:
    logger.error("âŒ éœ€è¦å®‰è£… requests åº“")
    logger.error("   è¿è¡Œ: pip install requests")
    requests = None

# åŒ—äº¬æ—¶åŒº (UTC+8)
BEIJING_TZ = timezone(timedelta(hours=8))

# API URLs
ALPHA_API_URL = "https://www.binance.com/bapi/defi/v1/public/wallet-direct/buw/wallet/cex/alpha/all/token/list"
FUTURES_API_URL = "https://fapi.binance.com/fapi/v1/exchangeInfo"

# ç¼“å­˜åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰
CACHE_REFRESH_INTERVAL = 60 * 60  # 1å°æ—¶

# ç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºŽæŒä¹…åŒ–ï¼Œé‡å¯åŽå¯å¿«é€ŸåŠ è½½ï¼‰
CACHE_FILE = Path(__file__).parent / "binance_alpha_intersection_cache.json"


def _get_proxies():
    """
    èŽ·å–ä»£ç†é…ç½®

    Returns:
        dict: requestsåº“ä½¿ç”¨çš„ä»£ç†é…ç½®ï¼Œå¦‚æžœæ²¡æœ‰é…ç½®åˆ™è¿”å›žNone
    """
    # ä¼˜å…ˆä½¿ç”¨ SOCKS5 ä»£ç†
    if SOCKS5_PROXY and isinstance(SOCKS5_PROXY, str) and SOCKS5_PROXY.strip():
        proxy_url = SOCKS5_PROXY.strip()
        return {
            'http': proxy_url,
            'https': proxy_url
        }

    # å…¶æ¬¡ä½¿ç”¨ HTTP ä»£ç†
    if HTTP_PROXY and isinstance(HTTP_PROXY, str) and HTTP_PROXY.strip():
        proxy_url = HTTP_PROXY.strip()
        return {
            'http': proxy_url,
            'https': proxy_url
        }

    # æ²¡æœ‰é…ç½®ä»£ç†
    return None


class BinanceAlphaCache:
    """
    å¸å®‰ Alpha ä¸Žåˆçº¦ä»£å¸äº¤é›†ç¼“å­˜
    è‡ªåŠ¨å®šæœŸåˆ·æ–°ï¼Œæä¾›å¿«é€ŸæŸ¥è¯¢æŽ¥å£
    """

    def __init__(self, refresh_interval=CACHE_REFRESH_INTERVAL):
        """
        åˆå§‹åŒ–ç¼“å­˜

        Args:
            refresh_interval: ç¼“å­˜åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶
        """
        self.refresh_interval = refresh_interval
        self._intersection_set = set()  # äº¤é›†ä»£å¸é›†åˆï¼ˆå¤§å†™ï¼‰
        self._last_update_time = None
        self._update_lock = threading.Lock()
        self._refresh_thread = None
        self._stop_flag = threading.Event()

        # æ˜¾ç¤ºä»£ç†é…ç½®ï¼ˆå¦‚æžœæœ‰ï¼‰
        proxies = _get_proxies()
        if proxies:
            proxy_url = proxies.get('https', proxies.get('http', ''))
            # éšè—å¯†ç éƒ¨åˆ†
            if '@' in proxy_url:
                parts = proxy_url.split('@')
                if len(parts) == 2:
                    protocol_user = parts[0].split('//')
                    if len(protocol_user) == 2:
                        protocol = protocol_user[0]
                        user_part = protocol_user[1].split(':')[0] if ':' in protocol_user[1] else protocol_user[1]
                        masked_url = f"{protocol}//{user_part}:***@{parts[1]}"
                        logger.info(f"ðŸŒ ä½¿ç”¨ä»£ç†: {masked_url}")
            else:
                logger.info(f"ðŸŒ ä½¿ç”¨ä»£ç†: {proxy_url}")
        else:
            logger.debug("ä¸ä½¿ç”¨ä»£ç†ï¼ˆç›´è¿žï¼‰")

        # å¯åŠ¨æ—¶å°è¯•ä»Žç¼“å­˜æ–‡ä»¶åŠ è½½
        self._load_from_cache_file()

        # å¦‚æžœç¼“å­˜ä¸ºç©ºæˆ–è¿‡æœŸï¼Œç«‹å³åˆ·æ–°
        if not self._intersection_set or self._is_cache_expired():
            logger.info("ç¼“å­˜ä¸ºç©ºæˆ–è¿‡æœŸï¼Œç«‹å³èŽ·å–å¸å®‰Alphaäº¤é›†...")
            self.refresh_now()

    def _is_cache_expired(self):
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ"""
        if not self._last_update_time:
            return True
        elapsed = time.time() - self._last_update_time
        return elapsed >= self.refresh_interval

    def _load_from_cache_file(self):
        """ä»Žç¼“å­˜æ–‡ä»¶åŠ è½½ï¼ˆå¦‚æžœå­˜åœ¨ï¼‰"""
        if not CACHE_FILE.exists():
            return

        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)

            timestamp = data.get('timestamp', 0)
            tokens = data.get('tokens', [])

            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆè¶…è¿‡2å€åˆ·æ–°é—´éš”è§†ä¸ºè¿‡æœŸï¼‰
            if time.time() - timestamp > self.refresh_interval * 2:
                logger.warning(f"ç¼“å­˜æ–‡ä»¶è¿‡æœŸï¼Œå°†é‡æ–°èŽ·å–")
                return

            self._intersection_set = set(token.upper() for token in tokens)
            self._last_update_time = timestamp

            logger.info(f"âœ… ä»Žç¼“å­˜æ–‡ä»¶åŠ è½½ {len(self._intersection_set)} ä¸ªå¸å®‰Alphaäº¤é›†ä»£å¸")
        except Exception as e:
            logger.warning(f"åŠ è½½ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")

    def _save_to_cache_file(self):
        """ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶"""
        try:
            data = {
                'timestamp': self._last_update_time,
                'tokens': sorted(self._intersection_set),
                'count': len(self._intersection_set),
                'updated_at': datetime.now(BEIJING_TZ).isoformat()
            }

            with open(CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            logger.debug(f"ç¼“å­˜å·²ä¿å­˜åˆ°æ–‡ä»¶: {CACHE_FILE}")
        except Exception as e:
            logger.warning(f"ä¿å­˜ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")

    def _get_alpha_tokens(self):
        """èŽ·å–å¸å®‰ Alpha ä»£å¸åˆ—è¡¨"""
        if not requests:
            return set()

        try:
            proxies = _get_proxies()
            response = requests.get(
                ALPHA_API_URL,
                headers={"User-Agent": "Mozilla/5.0"},
                proxies=proxies,
                timeout=15
            )
            response.raise_for_status()
            data = response.json()

            if data.get("code") != "000000":
                raise RuntimeError(f"API è¿”å›žé”™è¯¯: {data.get('message')}")

            tokens = data.get("data", [])
            alpha_symbols = set()

            for token in tokens:
                symbol = token.get("cexCoinName") or token.get("symbol")
                if symbol:
                    alpha_symbols.add(symbol.upper().strip())

            logger.debug(f"èŽ·å–åˆ° {len(alpha_symbols)} ä¸ª Alpha ä»£å¸")
            return alpha_symbols

        except Exception as e:
            logger.warning(f"èŽ·å– Alpha ä»£å¸å¤±è´¥: {e}")
            return set()

    def _get_futures_tokens(self):
        """èŽ·å–å¸å®‰åˆçº¦ä»£å¸åˆ—è¡¨ï¼ˆæ°¸ç»­åˆçº¦ï¼‰"""
        if not requests:
            return set()

        try:
            proxies = _get_proxies()
            response = requests.get(
                FUTURES_API_URL,
                headers={"User-Agent": "Mozilla/5.0"},
                proxies=proxies,
                timeout=20
            )
            response.raise_for_status()
            data = response.json()

            symbols_data = data.get("symbols", [])
            futures_symbols = set()

            for symbol_info in symbols_data:
                status = symbol_info.get("status") or symbol_info.get("contractStatus")
                if status != "TRADING":
                    continue

                contract_type = str(symbol_info.get("contractType", "")).upper()
                if contract_type != "PERPETUAL":
                    continue

                base_asset = symbol_info.get("baseAsset")
                if base_asset:
                    futures_symbols.add(base_asset.upper().strip())

            logger.debug(f"èŽ·å–åˆ° {len(futures_symbols)} ä¸ªåˆçº¦ä»£å¸")
            return futures_symbols

        except Exception as e:
            logger.warning(f"èŽ·å–åˆçº¦ä»£å¸å¤±è´¥: {e}")
            return set()

    def refresh_now(self):
        """
        ç«‹å³åˆ·æ–°ç¼“å­˜ï¼ˆåŒæ­¥æ–¹æ³•ï¼‰

        Returns:
            bool: åˆ·æ–°æˆåŠŸè¿”å›ž Trueï¼Œå¦åˆ™è¿”å›ž False
        """
        with self._update_lock:
            logger.info("ðŸ”„ å¼€å§‹åˆ·æ–°å¸å®‰Alphaäº¤é›†ç¼“å­˜...")

            # èŽ·å–ä¸¤ä¸ªåˆ—è¡¨
            alpha_tokens = self._get_alpha_tokens()
            futures_tokens = self._get_futures_tokens()

            if not alpha_tokens or not futures_tokens:
                logger.warning("âš ï¸ èŽ·å–ä»£å¸åˆ—è¡¨å¤±è´¥ï¼Œä¿ç•™æ—§ç¼“å­˜")
                return False

            # è®¡ç®—äº¤é›†
            intersection = alpha_tokens & futures_tokens

            if not intersection:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°äº¤é›†ä»£å¸ï¼Œä¿ç•™æ—§ç¼“å­˜")
                return False

            # æ›´æ–°ç¼“å­˜
            old_count = len(self._intersection_set)
            self._intersection_set = intersection
            self._last_update_time = time.time()

            # ä¿å­˜åˆ°æ–‡ä»¶
            self._save_to_cache_file()

            logger.info(f"âœ… ç¼“å­˜åˆ·æ–°æˆåŠŸ: {len(intersection)} ä¸ªäº¤é›†ä»£å¸ (æ—§: {old_count})")
            logger.info(f"   Alpha: {len(alpha_tokens)}, åˆçº¦: {len(futures_tokens)}")

            return True

    def is_in_intersection(self, symbol):
        """
        æ£€æŸ¥å¸ç§æ˜¯å¦åœ¨å¸å®‰Alphaä¸Žåˆçº¦äº¤é›†ä¸­

        Args:
            symbol: å¸ç§ç¬¦å·ï¼ˆå¦‚ 'BTC', 'ETH'ï¼Œä¸åŒºåˆ†å¤§å°å†™ï¼‰

        Returns:
            bool: åœ¨äº¤é›†ä¸­è¿”å›ž Trueï¼Œå¦åˆ™è¿”å›ž False
        """
        if not symbol:
            return False

        # ç»Ÿä¸€è½¬å¤§å†™
        symbol_upper = symbol.upper().strip()

        # åŽ»é™¤å¸¸è§åŽç¼€ï¼ˆå¦‚ /USDT, USDTï¼‰
        for suffix in ['/USDT', 'USDT', '/USD', 'USD']:
            if symbol_upper.endswith(suffix):
                symbol_upper = symbol_upper[:-len(suffix)]
                break

        return symbol_upper in self._intersection_set

    def get_intersection_list(self):
        """
        èŽ·å–äº¤é›†åˆ—è¡¨ï¼ˆæŽ’åºåŽï¼‰

        Returns:
            list: äº¤é›†ä»£å¸åˆ—è¡¨
        """
        return sorted(self._intersection_set)

    def get_cache_info(self):
        """
        èŽ·å–ç¼“å­˜ä¿¡æ¯

        Returns:
            dict: åŒ…å«ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        return {
            'count': len(self._intersection_set),
            'last_update': datetime.fromtimestamp(self._last_update_time, BEIJING_TZ).isoformat() if self._last_update_time else None,
            'is_expired': self._is_cache_expired(),
            'refresh_interval': self.refresh_interval
        }

    def start_auto_refresh(self):
        """
        å¯åŠ¨è‡ªåŠ¨åˆ·æ–°åŽå°çº¿ç¨‹
        """
        if self._refresh_thread and self._refresh_thread.is_alive():
            logger.warning("è‡ªåŠ¨åˆ·æ–°çº¿ç¨‹å·²åœ¨è¿è¡Œ")
            return

        self._stop_flag.clear()
        self._refresh_thread = threading.Thread(
            target=self._auto_refresh_loop,
            daemon=True,
            name="BinanceAlphaCacheRefresh"
        )
        self._refresh_thread.start()
        logger.info(f"âœ… å¯åŠ¨å¸å®‰Alphaç¼“å­˜è‡ªåŠ¨åˆ·æ–°çº¿ç¨‹ï¼ˆé—´éš”: {self.refresh_interval / 60:.0f} åˆ†é’Ÿï¼‰")

    def stop_auto_refresh(self):
        """
        åœæ­¢è‡ªåŠ¨åˆ·æ–°åŽå°çº¿ç¨‹
        """
        if not self._refresh_thread or not self._refresh_thread.is_alive():
            return

        logger.info("åœæ­¢å¸å®‰Alphaç¼“å­˜è‡ªåŠ¨åˆ·æ–°çº¿ç¨‹...")
        self._stop_flag.set()

        # ç­‰å¾…çº¿ç¨‹ç»“æŸï¼ˆæœ€å¤š5ç§’ï¼‰
        self._refresh_thread.join(timeout=5)

    def _auto_refresh_loop(self):
        """
        è‡ªåŠ¨åˆ·æ–°å¾ªçŽ¯ï¼ˆåŽå°çº¿ç¨‹ï¼‰
        """
        while not self._stop_flag.is_set():
            # ç­‰å¾…åˆ°ä¸‹æ¬¡åˆ·æ–°æ—¶é—´
            time_to_wait = self.refresh_interval
            if self._last_update_time:
                elapsed = time.time() - self._last_update_time
                time_to_wait = max(0, self.refresh_interval - elapsed)

            # åˆ†æ®µç­‰å¾…ï¼Œæ–¹ä¾¿å¿«é€Ÿå“åº”åœæ­¢ä¿¡å·
            wait_interval = 60  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡åœæ­¢æ ‡å¿—
            while time_to_wait > 0 and not self._stop_flag.is_set():
                sleep_time = min(wait_interval, time_to_wait)
                time.sleep(sleep_time)
                time_to_wait -= sleep_time

            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if self._stop_flag.is_set():
                break

            # æ‰§è¡Œåˆ·æ–°
            try:
                self.refresh_now()
            except Exception as e:
                logger.error(f"è‡ªåŠ¨åˆ·æ–°å¸å®‰Alphaç¼“å­˜å¤±è´¥: {e}")

        logger.info("å¸å®‰Alphaç¼“å­˜è‡ªåŠ¨åˆ·æ–°çº¿ç¨‹å·²åœæ­¢")


# å…¨å±€å•ä¾‹
_cache_instance = None


def get_binance_alpha_cache():
    """
    èŽ·å–å…¨å±€å¸å®‰Alphaç¼“å­˜å®žä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Returns:
        BinanceAlphaCache: ç¼“å­˜å®žä¾‹
    """
    global _cache_instance
    if _cache_instance is None:
        _cache_instance = BinanceAlphaCache()
    return _cache_instance


def is_binance_alpha_symbol(symbol):
    """
    ä¾¿æ·å‡½æ•°: æ£€æŸ¥å¸ç§æ˜¯å¦åœ¨å¸å®‰Alphaä¸Žåˆçº¦äº¤é›†ä¸­

    Args:
        symbol: å¸ç§ç¬¦å·

    Returns:
        bool: åœ¨äº¤é›†ä¸­è¿”å›ž Trueï¼Œå¦åˆ™è¿”å›ž False
    """
    cache = get_binance_alpha_cache()
    return cache.is_in_intersection(symbol)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("æµ‹è¯•å¸å®‰Alphaç¼“å­˜æ¨¡å—")
    print("=" * 60)

    cache = get_binance_alpha_cache()

    # æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
    info = cache.get_cache_info()
    print(f"ç¼“å­˜ä¿¡æ¯: {json.dumps(info, indent=2, ensure_ascii=False)}")
    print()

    # æµ‹è¯•æŸ¥è¯¢
    test_symbols = ['BTC', 'ETH', 'SOL', 'DOGE', 'XYZ123']
    print("æµ‹è¯•å¸ç§æŸ¥è¯¢:")
    for symbol in test_symbols:
        is_alpha = cache.is_in_intersection(symbol)
        status = "âœ…" if is_alpha else "âŒ"
        print(f"  {status} {symbol}: {'åœ¨äº¤é›†ä¸­' if is_alpha else 'ä¸åœ¨äº¤é›†ä¸­'}")
    print()

    # æ˜¾ç¤ºäº¤é›†åˆ—è¡¨ï¼ˆå‰10ä¸ªï¼‰
    intersection = cache.get_intersection_list()
    print(f"äº¤é›†ä»£å¸åˆ—è¡¨ï¼ˆå…± {len(intersection)} ä¸ªï¼‰:")
    print(f"  {', '.join(intersection[:10])}")
    if len(intersection) > 10:
        print(f"  ... è¿˜æœ‰ {len(intersection) - 10} ä¸ª")
